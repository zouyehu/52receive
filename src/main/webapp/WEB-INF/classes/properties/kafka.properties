#spring KafkaTemplate发送消息配置
#Kafka服务地址
kafkaTemplate.bootstrap.servers=192.168.1.240:9092
#消费者组id
kafkaTemplate.group.id=0
#批量发送字节数
kafkaTemplate.batch.size=16384
#生产者用来缓存待发送到服务器的记录内存总字节数
kafkaTemplate.buffer.memory=33554432
#缓冲区饱和后最大阻塞时间
kafkaTemplate.max.block.ms=60000
kafkaTemplate.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafkaTemplate.value.serializer=org.apache.kafka.common.serialization.StringSerializer
#为false会缓冲提交数据，批量flush，性能提升，存在数据丢失风险
kafkaTemplate.autoFlush=true


#kafka-client消费端配置，订阅方式消费消息，可同时订阅多个主题
#Kafka服务地址
consumer.subscribe.bootstrap.servers=192.168.1.240:9092
#消费者组id
consumer.subscribe.group.id=0
#偏移量提交策略，设为自动提交
consumer.subscribe.enable.auto.commit=true
#自动提交偏移量时间间隔
consumer.subscribe.auto.commit.interval.ms=1000
#没有初始偏移量或当前偏移量超出范围时采取的操作，earliest（最早的）或latest（最新的）
consumer.subscribe.auto.offset.reset=earliest
consumer.subscribe.session.timeout.ms=30000
#每次获取的记录条数
consumer.subscribe.max.poll.records=1000
consumer.subscribe.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
consumer.subscribe.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

#kafka-client消费端配置，非订阅方式消费消息，针对单个主题
#Kafka服务地址
consumer.bootstrap.servers=192.168.1.240:9092
#偏移量提交策略，设为自动提交
consumer.enable.auto.commit=true
#自动提交偏移量时间间隔
consumer.auto.commit.interval.ms=1000
#没有初始偏移量或当前偏移量超出范围时采取的操作，earliest（最早的）或latest（最新的）
consumer.auto.offset.reset=earliest
consumer.session.timeout.ms=10000
consumer.request.timeout.ms=12000
#每次获取的记录条数
consumer.max.poll.records=500
consumer.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
consumer.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer


#zookeeper配置，用于创建、删除主题操作
zookeeper.url=192.168.1.240:2181
zookeeper.sessionTimeout=30000
zookeeper.connectionTimeout=30000

